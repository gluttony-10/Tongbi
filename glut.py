import warnings
warnings.filterwarnings("ignore", category=FutureWarning, module="timm.models.layers")
warnings.filterwarnings("ignore", category=FutureWarning, module="timm.models.registry")
warnings.filterwarnings("ignore", category=UserWarning, module="controlnet_aux.segment_anything.modeling.tiny_vit_sam")
import io
import os
import json
import time
import base64
import torch
import numpy as np
import psutil
import gradio as gr
from openai import OpenAI
import requests
import argparse
from PIL import Image
from diffusers.utils import load_image
from utils.camera_control import CameraControl3D
from utils.prompt_enhancer import enhance_prompt, enhance_prompt_edit2
from utils.image_utils import exchange_width_height, adjust_width_height, adjust_width_height_editplus2
from utils.config_utils import initialize_examples_file, save_tab_model, load_tab_models, load_examples, save_example
from utils.gallery_utils import load_gallery, refresh_gallery, load_image_info
from utils.model_loader import load_model
from utils.camera_utils import build_camera_prompt, update_dimensions_on_upload_camera
from utils.ui_utils import stop_generate, change_reference_count, scale_resolution_1_5, find_port, update_selection, load_image_info_wrapper, generate_cont, save_openai_config
from utils.generator import generate_t2i, generate_i2i, generate_inp, generate_editplus2, generate_camera_edit
import utils.state as state

parser = argparse.ArgumentParser() 
parser.add_argument("--server_name", type=str, default="127.0.0.1", help="IPåœ°å€ï¼Œå±€åŸŸç½‘è®¿é—®æ”¹ä¸º0.0.0.0")
parser.add_argument("--server_port", type=int, default=7891, help="ä½¿ç”¨ç«¯å£")
parser.add_argument("--share", action="store_true", help="æ˜¯å¦å¯ç”¨gradioå…±äº«")
parser.add_argument("--mcp_server", action="store_true", help="æ˜¯å¦å¯ç”¨mcpæœåŠ¡")
parser.add_argument("--compile", action="store_true", help="æ˜¯å¦å¯ç”¨compileåŠ é€Ÿ")
args = parser.parse_args()

print(" å¯åŠ¨ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾… bilibili@åå­—é±¼ https://space.bilibili.com/893892")
print(f'\033[32mPytorchç‰ˆæœ¬ï¼š{torch.__version__}\033[0m')
if torch.cuda.is_available():
    device = "cuda" 
    print(f'\033[32mæ˜¾å¡å‹å·ï¼š{torch.cuda.get_device_name()}\033[0m')
    total_vram_in_gb = torch.cuda.get_device_properties(0).total_memory / 1073741824
    print(f'\033[32mæ˜¾å­˜å¤§å°ï¼š{total_vram_in_gb:.2f}GB\033[0m')
    mem = psutil.virtual_memory()
    print(f'\033[32må†…å­˜å¤§å°ï¼š{mem.total/1073741824:.2f}GB\033[0m')
    if torch.cuda.get_device_capability()[0] >= 8:
        print(f'\033[32mæ”¯æŒBF16\033[0m')
        dtype = torch.bfloat16
    else:
        print(f'\033[32mä¸æ”¯æŒBF16ï¼Œä½¿ç”¨FP32\033[0m')
        dtype = torch.float32
else:
    print(f'\033[32mCUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥\033[0m')
    device = "cpu"

# å¯ç”¨ CUDA åŠ é€Ÿä¼˜åŒ–
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True  # è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜å·ç§¯ç®—æ³•
    torch.backends.cuda.matmul.allow_tf32 = True  # å…è®¸ TF32 çŸ©é˜µä¹˜æ³•
    torch.backends.cudnn.allow_tf32 = True  # å…è®¸ TF32 åŠ é€Ÿ

#åˆå§‹åŒ–ï¼ˆä½¿ç”¨å…¨å±€çŠ¶æ€æ¨¡å—ï¼‰
state.config = {}
state.transformer_choices = []
state.transformer_choices2 = []
state.t2i_choices = []
state.transformer_loaded = None
state.lora_choices = []
state.lora_loaded = None
state.lora_loaded_weights = None
state.image_loaded = None
state.mode = None
state.mode_loaded = None
state.pipe = None
state.prompt_cache = None
state.negative_prompt_cache = None
state.model_id = "models/Qwen-Image"
state.stop_generation = False
state.mmgp = None
state.device = device
state.dtype = dtype
state.args = args
state.mem = mem

# ä¸ºäº†å…¼å®¹æ€§ï¼Œåˆ›å»ºå±€éƒ¨å˜é‡å¼•ç”¨
config = state.config
transformer_choices = state.transformer_choices
transformer_choices2 = state.transformer_choices2
t2i_choices = state.t2i_choices
transformer_loaded = state.transformer_loaded
lora_choices = state.lora_choices
lora_loaded = state.lora_loaded
lora_loaded_weights = state.lora_loaded_weights
image_loaded = state.image_loaded
mode = state.mode
mode_loaded = state.mode_loaded
pipe = state.pipe
prompt_cache = state.prompt_cache
negative_prompt_cache = state.negative_prompt_cache
model_id = state.model_id
stop_generation = state.stop_generation
mmgp = state.mmgp
prompt_embeds_cache = state.prompt_embeds_cache

EXAMPLES_FILE = "json/prompts.json"

#ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
os.makedirs("outputs", exist_ok=True)
#ç¡®ä¿jsonæ–‡ä»¶å¤¹å­˜åœ¨
os.makedirs("json", exist_ok=True)
#è¯»å–è®¾ç½®
CONFIG_FILE = "json/config.json"

# åˆå§‹åŒ–æ¨¡å‹åˆ—è¡¨ï¼ˆåœ¨UIåˆ›å»ºå‰ï¼‰
def init_model_choices():
    """åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©åˆ—è¡¨ï¼ˆä½¿ç”¨å›ºå®šæ¨¡å‹ï¼Œä¸æ‰«æç›®å½•ï¼‰"""
    global transformer_choices, transformer_choices2, t2i_choices, controlnet_processor_choices
    # åŒæ­¥åˆ°å…¨å±€çŠ¶æ€
    state.transformer_choices = transformer_choices
    state.transformer_choices2 = transformer_choices2
    state.t2i_choices = t2i_choices
    
    # å›ºå®šåŸºç¡€æ¨¡å‹ï¼ˆç”¨äºå›¾ç”Ÿå›¾ã€å±€éƒ¨é‡ç»˜ï¼‰
    base_model_full = "Qwen-Image-2512-Lightning-4steps-V1.0-mmgp.safetensors"
    base_model_display = base_model_full.replace(".safetensors", "")  # æ˜¾ç¤ºæ—¶å»æ‰åç¼€
    transformer_choices = [base_model_display]
    
    # æ–‡ç”Ÿå›¾æ¨¡å‹ï¼ˆåŒ…å«æœ¬åœ°æ¨¡å‹å’ŒMS-Qwen-Imageã€MS-Qwen-Image-2512å’ŒMS-Z-Image-Turboäº‘ç«¯é€‰é¡¹ï¼‰
    t2i_choices = [base_model_display, "MS-Qwen-Image", "MS-Qwen-Image-2512", "MS-Z-Image-Turbo"]
    
    # ç¼–è¾‘æ¨¡å‹ï¼ˆç”¨äºå¤šå›¾ç¼–è¾‘ã€3Dç›¸æœºæ§åˆ¶ï¼‰- åŒ…å«æœ¬åœ°æ¨¡å‹å’ŒMSé€‰é¡¹
    edit_model_full = "Qwen-Image-Edit-2511-Lightning-4steps-V1.0-mmgp.safetensors"
    edit_model_display = edit_model_full.replace(".safetensors", "")  # æ˜¾ç¤ºæ—¶å»æ‰åç¼€
    transformer_choices2 = [edit_model_display, "MS-Qwen-Image-Edit-2509", "MS-Qwen-Image-Edit-2511"]
    
    # ControlNeté¢„å¤„ç†é€‰é¡¹åˆ—è¡¨
    controlnet_processor_choices = [
        "canny", "depth_leres", "depth_leres++", "depth_midas", "depth_zoe", 
        "lineart_anime", "lineart_coarse", "lineart_realistic", "mediapipe_face", 
        "mlsd", "normal_bae", "openpose", "openpose_face", 
        "openpose_faceonly", "openpose_full", "openpose_hand", "scribble_hed", 
        "scribble_pidinet", "shuffle", "softedge_hed", "softedge_hedsafe", 
        "softedge_pidinet", "softedge_pidsafe"
    ]

# åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©
init_model_choices()
if os.path.exists(CONFIG_FILE):
    with open(CONFIG_FILE, "r", encoding="utf-8") as f:
        config = json.load(f)
else:
    config = {}

# æ¯ä¸ªTabItemçš„æ¨¡å‹é€‰æ‹©ï¼ˆä»ç‹¬ç«‹çš„JSONæ–‡ä»¶åŠ è½½ï¼‰
tab_models = load_tab_models()
default_t2i_model = "Qwen-Image-2512-Lightning-4steps-V1.0-mmgp"
transformer_t2i = tab_models.get("t2i", default_t2i_model)
# å¦‚æœä¿å­˜çš„æ˜¯æ—§åç§°ï¼Œè‡ªåŠ¨è¿ç§»åˆ°æ–°åç§°
if transformer_t2i == "ModelScope-QI.safetensors" or transformer_t2i == "ModelScope-QI":
    transformer_t2i = "MS-Qwen-Image"

transformer_i2i = tab_models.get("i2i", default_t2i_model)

transformer_inp = tab_models.get("inp", default_t2i_model)

default_edit_model = "Qwen-Image-Edit-2511-Lightning-4steps-V1.0-mmgp"
transformer_editplus = tab_models.get("editplus", default_edit_model)

transformer_camera = tab_models.get("camera", default_edit_model)
res_vram = float(config.get("RES_VRAM", "1500"))
state.res_vram = res_vram  # ç”Ÿæˆæ—¶åªä½¿ç”¨å·²ä¿å­˜çš„è®¾ç½®
openai_base_url = config.get("OPENAI_BASE_URL", "https://open.bigmodel.cn/api/paas/v4")
openai_api_key = config.get("OPENAI_API_KEY", "")
model_name = config.get("MODEL_NAME", "GLM-4.6V-Flash")
temperature = float(config.get("TEMPERATURE", "0.8"))
top_p = float(config.get("TOP_P", "0.6"))
max_tokens = float(config.get("MAX_TOKENS", "16384"))
modelscope_api_key = config.get("MODELSCOPE_API_KEY", "")
image_format = config.get("IMAGE_FORMAT", "png").lower()  # å›¾ç‰‡ä¿å­˜æ ¼å¼ï¼Œé»˜è®¤png
state.image_format = image_format  # åŒæ­¥åˆ°å…¨å±€çŠ¶æ€ï¼Œä½¿è®¾ç½®é‡Œçš„ webp ç­‰æ ¼å¼ç”Ÿæ•ˆ


def refresh_model():
    """åªåˆ·æ–° LoRA æ¨¡å‹åˆ—è¡¨"""
    global lora_choices
    
    lora_dir = "models/lora/Qwen-Image"  # åªè¯»å–Qwen-Imageæ–‡ä»¶å¤¹
    
    if os.path.exists(lora_dir):
        lora_files = [f for f in os.listdir(lora_dir) if f.endswith(".safetensors")]
        lora_choices = sorted(lora_files)
    else:
        lora_choices = []
        if not os.path.exists("models/lora"):
            print("models/loraæ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        elif not os.path.exists(lora_dir):
            print(f"models/lora/Qwen-Imageæ–‡ä»¶å¤¹ä¸å­˜åœ¨")
    
    # åªæ›´æ–° LoRA ä¸‹æ‹‰æ¡†ï¼Œå…¶ä»–ç»„ä»¶ä¸æ›´æ–°
    return (
        gr.Dropdown(),  # transformer_dropdown (ä¸æ›´æ–°)
        gr.Dropdown(choices=lora_choices, multiselect=True),  # lora_dropdown (åªæ›´æ–°LoRA)
        gr.Dropdown(),  # transformer_t2i (ä¸æ›´æ–°)
        gr.Dropdown(),  # transformer_i2i (ä¸æ›´æ–°)
        gr.Dropdown(),  # transformer_inp (ä¸æ›´æ–°)
        gr.Dropdown(),  # transformer_editplus (ä¸æ›´æ–°)
        gr.Dropdown(),  # transformer_camera (ä¸æ›´æ–°)
    )

initialize_examples_file()
refresh_model()


# load_model å·²ç§»è‡³ utils.model_loaderï¼Œè¿™é‡Œä¿ç•™åŒ…è£…å‡½æ•°ä»¥åŒæ­¥å…¨å±€çŠ¶æ€
def load_model_wrapper(mode, transformer_dropdown, lora_dropdown, lora_weights, res_vram):
    """åŒ…è£… load_model ä»¥åŒæ­¥å…¨å±€çŠ¶æ€"""
    from utils.model_loader import load_model
    load_model(mode, transformer_dropdown, lora_dropdown, lora_weights, res_vram)
    # åŒæ­¥çŠ¶æ€
    global pipe, mode_loaded, transformer_loaded, lora_loaded, lora_loaded_weights, mmgp
    pipe = state.pipe
    mode_loaded = state.mode_loaded
    transformer_loaded = state.transformer_loaded
    lora_loaded = state.lora_loaded
    lora_loaded_weights = state.lora_loaded_weights
    mmgp = state.mmgp

# ä¸ºäº†å…¼å®¹æ€§ï¼Œåˆ›å»ºåˆ«å
load_model = load_model_wrapper

css = """
.icon-btn {
    min-width: unset !important;
    display: flex !important;
    align-items: center !important;
    justify-content: center !important;
}
.refresh-btn {
    min-width: 36px !important;
    width: 36px !important;
    height: 36px !important;
    max-width: 36px !important;
    max-height: 36px !important;
    padding: 0 !important;
    margin: 0 !important;
    display: flex !important;
    align-items: center !important;
    justify-content: center !important;
    font-size: 16px !important;
    line-height: 1 !important;
    border-radius: 4px !important;
}
#camera-3d-control { min-height: 450px; }
.slider-row { display: flex; gap: 10px; align-items: center; }
"""


with gr.Blocks() as demo:
    gr.Markdown("""
            <div>
                <h2 style="font-size: 30px;text-align: center;">é€šè‡‚ Tongbi</h2>
            </div>
            <div style="text-align: center;">
                åå­—é±¼
                <a href="https://space.bilibili.com/893892">ğŸŒbilibili</a> 
                |Tongbi
                <a href="https://github.com/gluttony-10/Tongbi">ğŸŒgithub</a> 
            </div>
            """)
    with gr.Row():
        # é¡µé¢é€‰æ‹©ä¸‹æ‹‰æ¡†
        page_choices = ["æ–‡ç”Ÿå›¾", "å›¾ç”Ÿå›¾", "å±€éƒ¨é‡ç»˜", "å¤šå›¾ç¼–è¾‘", "3Dç›¸æœºæ§åˆ¶", "ControlNeté¢„å¤„ç†", "å›¾åº“", "è®¾ç½®"]
        page_dropdown = gr.Dropdown(label="åŠŸèƒ½é€‰æ‹©", info="ç¬¬ä¸€æ¬¡æ‰“å¼€ï¼Œè¯·å…ˆé€‰æ‹©è®¾ç½®", choices=page_choices, value="æ–‡ç”Ÿå›¾", scale=1)
        transformer_dropdown = gr.Dropdown(label="æ¨¡å‹é€‰æ‹©", info="MSå¼€å¤´ä¸ºäº‘ç«¯æ¨¡å‹ï¼Œè°ƒç”¨API", choices=t2i_choices, value=transformer_t2i if transformer_t2i in t2i_choices else (t2i_choices[0] if t2i_choices else None), scale=2)
        lora_dropdown = gr.Dropdown(label="LoRAæ¨¡å‹", info="ä¸‹è½½LoRAåˆ°models/lora/å¯¹åº”ç›®å½•ï¼Œå¯å¤šé€‰", choices=lora_choices, multiselect=True, scale=2)
        lora_weights = gr.Textbox(label="LoRAæƒé‡", info="å¤šä¸ªæƒé‡è¯·ç”¨è‹±æ–‡é€—å·éš”å¼€ã€‚ä¾‹å¦‚ï¼š0.8,0.5,0.2", value="", scale=2)
        refresh_button = gr.Button("ğŸ”„", scale=0, min_width=36, elem_classes="refresh-btn")
    
    # ç”¨äºè·Ÿè¸ªå½“å‰é€‰ä¸­çš„æ¨¡å‹å€¼ï¼ˆåˆå§‹åŒ–ä¸ºæ–‡ç”Ÿå›¾æ¨¡å‹çš„ç¬¬ä¸€ä¸ªé€‰é¡¹ï¼‰
    initial_model_value = transformer_t2i if transformer_t2i in t2i_choices else (t2i_choices[0] if t2i_choices else None)
    current_model_value = gr.State(value=initial_model_value)
    
    # æ–‡ç”Ÿå›¾é¡µé¢
    with gr.Column(visible=True) as page_t2i:
        with gr.Row():
            with gr.Column():
                # æ–‡ç”Ÿå›¾ä½¿ç”¨t2i_choicesï¼ˆåŒ…å«MS-Qwen-Imageã€MS-Qwen-Image-2512å’ŒMS-Z-Image-Turboï¼‰
                # æ³¨æ„ï¼št2i_choices å·²ç»åŒ…å«æ‰€æœ‰é€‰é¡¹ï¼Œç›´æ¥ä½¿ç”¨
                transformer_t2i = gr.Dropdown(label="åŸºç¡€æ¨¡å‹", choices=t2i_choices, value=transformer_t2i if transformer_t2i in t2i_choices else (t2i_choices[0] if t2i_choices else None), interactive=True, visible=False)
                prompt = gr.Textbox(label="æç¤ºè¯", value="è¶…æ¸…ï¼Œ4Kï¼Œç”µå½±çº§æ„å›¾ï¼Œ")
                negative_prompt = gr.Textbox(label="è´Ÿé¢æç¤ºè¯", value="")
                with gr.Row():
                    generate_button = gr.Button("ğŸ–¼ï¸ å¼€å§‹ç”Ÿæˆ", variant='primary', scale=5)
                    enhance_button = gr.Button("âœ¨ æç¤ºè¯å¢å¼º", scale=2)
                    save_example_button = gr.Button("ğŸ’¾ ä¿å­˜æç¤ºè¯", scale=2)
                with gr.Accordion("å‚æ•°è®¾ç½®", open=True):
                    gr.Markdown("æ¨èåˆ†è¾¨ç‡ï¼š1328x1328ã€1664x928ã€1472x1104")
                    with gr.Row():
                        width = gr.Slider(label="å®½åº¦", minimum=256, maximum=3072, step=16, value=1328)
                        height = gr.Slider(label="é«˜åº¦", minimum=256, maximum=3072, step=16, value=1328)
                    with gr.Row():
                        exchange_button = gr.Button("ğŸ”„ äº¤æ¢å®½é«˜")
                        scale_1_5_button = gr.Button("ğŸ“ 1.5å€åˆ†è¾¨ç‡")
                    batch_images = gr.Slider(label="æ‰¹é‡ç”Ÿæˆ", minimum=1, maximum=100, step=1, value=1)
                    num_inference_steps = gr.Slider(label="é‡‡æ ·æ­¥æ•°ï¼ˆæ¨è4æ­¥ï¼‰", minimum=1, maximum=100, step=1, value=4)
                    true_cfg_scale = gr.Slider(label="true cfg scale", minimum=1, maximum=10, step=0.1, value=1.0)
                    seed_param = gr.Number(label="ç§å­ï¼Œè¯·è¾“å…¥è‡ªç„¶æ•°ï¼Œ-1ä¸ºéšæœº", value=-1)
            with gr.Column():
                info = gr.Textbox(label="æç¤ºä¿¡æ¯", interactive=False)
                image_output = gr.Gallery(label="ç”Ÿæˆç»“æœ", interactive=False)
                stop_button = gr.Button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", variant="stop")
                examples_dropdown = gr.Dropdown(
                    label="æç¤ºè¯åº“", 
                    choices=load_examples("t2i"),
                    interactive=True,
                    scale=5
                )
    # å›¾ç”Ÿå›¾é¡µé¢
    with gr.Column(visible=False) as page_i2i:
        with gr.Row():
            with gr.Column():
                transformer_i2i = gr.Dropdown(label="åŸºç¡€æ¨¡å‹", choices=transformer_choices, value=transformer_i2i if transformer_i2i in transformer_choices else (transformer_choices[0] if transformer_choices else None), interactive=True, visible=False)
                image_i2i = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=400)
                prompt_i2i = gr.Textbox(label="æç¤ºè¯", value="è¶…æ¸…ï¼Œ4Kï¼Œç”µå½±çº§æ„å›¾ï¼Œ")
                negative_prompt_i2i = gr.Textbox(label="è´Ÿé¢æç¤ºè¯", value="")
                with gr.Row():
                    generate_button_i2i = gr.Button("ğŸ–¼ï¸ å¼€å§‹ç”Ÿæˆ", variant='primary', scale=4)
                    enhance_button_i2i = gr.Button("âœ¨ æç¤ºè¯å¢å¼º", scale=2)
                    reverse_button_i2i = gr.Button("ğŸ” åæ¨æç¤ºè¯", scale=2)
                    save_example_button_i2i = gr.Button("ğŸ’¾ ä¿å­˜æç¤ºè¯", scale=2)
                with gr.Accordion("å‚æ•°è®¾ç½®", open=True):
                    gr.Markdown("ä¸Šä¼ å›¾åƒååˆ†è¾¨ç‡è‡ªåŠ¨è®¡ç®—")
                    with gr.Row():
                        width_i2i = gr.Slider(label="å®½åº¦", minimum=256, maximum=3072, step=16, value=1328)
                        height_i2i = gr.Slider(label="é«˜åº¦", minimum=256, maximum=3072, step=16, value=1328)
                    with gr.Row():
                        exchange_button_i2i = gr.Button("ğŸ”„ äº¤æ¢å®½é«˜")
                        scale_1_5_button_i2i = gr.Button("ğŸ“ 1.5å€åˆ†è¾¨ç‡")
                    strength_i2i = gr.Slider(label="strength", minimum=0, maximum=1, step=0.01, value=0.5)
                    batch_images_i2i = gr.Slider(label="æ‰¹é‡ç”Ÿæˆ", minimum=1, maximum=100, step=1, value=1)
                    num_inference_steps_i2i = gr.Slider(label="é‡‡æ ·æ­¥æ•°ï¼ˆæ¨è4æ­¥ï¼‰", minimum=1, maximum=100, step=1, value=4)
                    true_cfg_scale_i2i = gr.Slider(label="true cfg scale", minimum=1, maximum=10, step=0.1, value=1.0)
                    seed_param_i2i = gr.Number(label="ç§å­ï¼Œè¯·è¾“å…¥è‡ªç„¶æ•°ï¼Œ-1ä¸ºéšæœº", value=-1)
            with gr.Column():
                info_i2i = gr.Textbox(label="æç¤ºä¿¡æ¯", interactive=False)
                image_output_i2i = gr.Gallery(label="ç”Ÿæˆç»“æœ", interactive=False)
                stop_button_i2i = gr.Button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", variant="stop")
                examples_dropdown_i2i = gr.Dropdown(
                    label="æç¤ºè¯åº“", 
                    choices=load_examples("i2i"),
                    interactive=True,
                    scale=5
                )
    # å±€éƒ¨é‡ç»˜é¡µé¢
    with gr.Column(visible=False) as page_inp:
        with gr.Row():
            with gr.Column():
                transformer_inp = gr.Dropdown(label="åŸºç¡€æ¨¡å‹", choices=transformer_choices, value=transformer_inp if transformer_inp in transformer_choices else (transformer_choices[0] if transformer_choices else None), interactive=True, visible=False)
                image_inp = gr.ImageMask(label="è¾“å…¥è’™ç‰ˆ", type="pil", height=400)
                prompt_inp = gr.Textbox(label="æç¤ºè¯", value="è¶…æ¸…ï¼Œ4Kï¼Œç”µå½±çº§æ„å›¾ï¼Œ")
                negative_prompt_inp = gr.Textbox(label="è´Ÿé¢æç¤ºè¯", value="")
                with gr.Row():
                    generate_button_inp = gr.Button("ğŸ–¼ï¸ å¼€å§‹ç”Ÿæˆ", variant='primary', scale=4)
                    enhance_button_inp = gr.Button("âœ¨ æç¤ºè¯å¢å¼º", scale=2)
                    reverse_button_inp = gr.Button("ğŸ” åæ¨æç¤ºè¯", scale=2)
                    save_example_button_inp = gr.Button("ğŸ’¾ ä¿å­˜æç¤ºè¯", scale=2)
                with gr.Accordion("å‚æ•°è®¾ç½®", open=True):
                    gr.Markdown("ä¸Šä¼ å›¾åƒååˆ†è¾¨ç‡è‡ªåŠ¨è®¡ç®—")
                    with gr.Row():
                        width_inp = gr.Slider(label="å®½åº¦", minimum=256, maximum=3072, step=16, value=1328)
                        height_inp = gr.Slider(label="é«˜åº¦", minimum=256, maximum=3072, step=16, value=1328)
                    with gr.Row():
                        exchange_button_inp = gr.Button("ğŸ”„ äº¤æ¢å®½é«˜")
                        scale_1_5_button_inp = gr.Button("ğŸ“ 1.5å€åˆ†è¾¨ç‡")
                    strength_inp = gr.Slider(label="strength", minimum=0, maximum=1, step=0.01, value=0.8)
                    batch_images_inp = gr.Slider(label="æ‰¹é‡ç”Ÿæˆ", minimum=1, maximum=100, step=1, value=1)
                    num_inference_steps_inp = gr.Slider(label="é‡‡æ ·æ­¥æ•°ï¼ˆæ¨è4æ­¥ï¼‰", minimum=1, maximum=100, step=1, value=4)
                    true_cfg_scale_inp = gr.Slider(label="true cfg scale", minimum=1, maximum=10, step=0.1, value=1.0)
                    seed_param_inp = gr.Number(label="ç§å­ï¼Œè¯·è¾“å…¥è‡ªç„¶æ•°ï¼Œ-1ä¸ºéšæœº", value=-1)
            with gr.Column():
                info_inp = gr.Textbox(label="æç¤ºä¿¡æ¯", interactive=False)
                image_output_inp = gr.Gallery(label="ç”Ÿæˆç»“æœ", interactive=False)
                stop_button_inp = gr.Button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", variant="stop")
                examples_dropdown_inp = gr.Dropdown(
                    label="æç¤ºè¯åº“", 
                    choices=load_examples("inp"),
                    interactive=True,
                    scale=5
                )
    # å¤šå›¾ç¼–è¾‘é¡µé¢
    with gr.Column(visible=False) as page_editplus:
        with gr.Row():
            with gr.Column():
                transformer_editplus = gr.Dropdown(label="ç¼–è¾‘æ¨¡å‹", choices=transformer_choices2, value=transformer_editplus if transformer_editplus in transformer_choices2 else (transformer_choices2[0] if transformer_choices2 else None), interactive=True, visible=False)
                with gr.Row():
                    image_editplus2 = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=300, image_mode="RGBA")
                    image_editplus3 = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=300, image_mode="RGBA", visible=False)
                    image_editplus4 = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=300, image_mode="RGBA", visible=False)
                    image_editplus5 = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=300, image_mode="RGBA", visible=False)
                reference_count = gr.Slider(
                    label="å‚è€ƒå›¾æ•°é‡", 
                    minimum=0, 
                    maximum=3, 
                    step=1, 
                    value=0,
                )
                prompt_editplus2 = gr.Textbox(label="æç¤ºè¯", value="ç»™å·¦è¾¹çš„å¥³å­©æ¢ä¸Šå³è¾¹çš„è¡£æœ")
                negative_prompt_editplus2 = gr.Textbox(label="è´Ÿé¢æç¤ºè¯", value="")
                with gr.Row():
                    generate_button_editplus2 = gr.Button("ğŸ–¼ï¸ å¼€å§‹ç”Ÿæˆ", variant='primary', scale=4)
                    enhance_button_editplus2 = gr.Button("âœ¨ æç¤ºè¯å¢å¼º", scale=2)
                    reverse_button_editplus2 = gr.Button("ğŸ” åæ¨æç¤ºè¯", scale=2)
                    save_example_button_editplus2 = gr.Button("ğŸ’¾ ä¿å­˜æç¤ºè¯", scale=2)
                with gr.Accordion("å‚æ•°è®¾ç½®", open=True):
                    gr.Markdown("ä¸Šä¼ å›¾åƒååˆ†è¾¨ç‡è‡ªåŠ¨è®¡ç®—")
                    with gr.Row():
                        width_editplus2 = gr.Slider(label="å®½åº¦", minimum=256, maximum=3072, step=16, value=1024)
                        height_editplus2 = gr.Slider(label="é«˜åº¦", minimum=256, maximum=3072, step=16, value=1024)
                    with gr.Row():
                        exchange_button_editplus2 = gr.Button("ğŸ”„ äº¤æ¢å®½é«˜")
                        scale_1_5_button_editplus2 = gr.Button("ğŸ“ 1.5å€åˆ†è¾¨ç‡")
                    batch_images_editplus2 = gr.Slider(label="æ‰¹é‡ç”Ÿæˆ", minimum=1, maximum=100, step=1, value=1)
                    num_inference_steps_editplus2 = gr.Slider(label="é‡‡æ ·æ­¥æ•°ï¼ˆæ¨è4æ­¥ï¼‰", minimum=1, maximum=100, step=1, value=4)
                    true_cfg_scale_editplus2 = gr.Slider(label="true cfg scale", minimum=1, maximum=10, step=0.1, value=1.0)
                    seed_param_editplus2 = gr.Number(label="ç§å­ï¼Œè¯·è¾“å…¥è‡ªç„¶æ•°ï¼Œ-1ä¸ºéšæœº", value=0)
            with gr.Column():
                info_editplus2 = gr.Textbox(label="æç¤ºä¿¡æ¯", interactive=False)
                image_output_editplus2 = gr.Gallery(label="ç”Ÿæˆç»“æœ", interactive=False)
                stop_button_editplus2 = gr.Button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", variant="stop")
                examples_dropdown_editplus2 = gr.Dropdown(
                    label="æç¤ºè¯åº“", 
                    choices=load_examples("editplus"),
                    interactive=True,
                    scale=5
                )
    # 3Dç›¸æœºæ§åˆ¶é¡µé¢
    with gr.Column(visible=False) as page_camera:
        with gr.Row():
            # Left column: Input image and controls
            with gr.Column(scale=1):
                transformer_camera = gr.Dropdown(label="ç¼–è¾‘æ¨¡å‹", choices=transformer_choices2, value=transformer_camera if transformer_camera in transformer_choices2 else (transformer_choices2[0] if transformer_choices2 else None), interactive=True, visible=False)
                with gr.Row():
                    image_camera = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=500)
                    with gr.Column():
                        camera_3d = CameraControl3D(
                            value={"azimuth": 0, "elevation": 0, "distance": 1.0},
                            elem_id="camera-3d-control"
                        )
                        gr.Markdown("*æ‹–åŠ¨å½©è‰²æ‰‹æŸ„ï¼šğŸŸ¢ æ–¹ä½è§’ï¼ŒğŸ©· ä»°è§’ï¼ŒğŸŸ¡ è·ç¦»ï¼ˆä¸Šè¿œä¸‹è¿‘ï¼‰*")
                with gr.Row():
                    run_btn_camera = gr.Button("ğŸ–¼ï¸ ç”Ÿæˆ", variant="primary", scale=4)
                    enhance_button_camera = gr.Button("âœ¨ æç¤ºè¯å¢å¼º", scale=2)
                    reverse_button_camera = gr.Button("ğŸ” åæ¨æç¤ºè¯", scale=2)
                    save_example_button_camera = gr.Button("ğŸ’¾ ä¿å­˜æç¤ºè¯", scale=2)
                with gr.Accordion("æ»‘å—æ§åˆ¶", open=True):
                    azimuth_slider = gr.Slider(
                        label="æ–¹ä½è§’ï¼ˆæ°´å¹³æ—‹è½¬ï¼‰",
                        minimum=0,
                        maximum=315,
                        step=45,
                        value=0,
                        info="0Â°=æ­£é¢ï¼Œ90Â°=å³ä¾§ï¼Œ180Â°=èƒŒé¢ï¼Œ270Â°=å·¦ä¾§"
                    )
                    elevation_slider = gr.Slider(
                        label="ä»°è§’ï¼ˆå‚ç›´è§’åº¦ï¼‰", 
                        minimum=-30,
                        maximum=60,
                        step=30,
                        value=0,
                        info="-30Â°=ä½è§’åº¦ï¼Œ0Â°=å¹³è§†ï¼Œ60Â°=é«˜è§’åº¦"
                    )
                    distance_slider = gr.Slider(
                        label="è·ç¦»",
                        minimum=0.6,
                        maximum=1.4,
                        step=0.4,
                        value=1.0,
                        info="0.6=ç‰¹å†™ï¼Œ1.0=ä¸­æ™¯ï¼Œ1.4=å…¨æ™¯"
                    )
                    prompt_preview_camera = gr.Textbox(
                        label="ç”Ÿæˆçš„æç¤ºè¯",
                        value="<sks> front view eye-level shot medium shot",
                        interactive=False
                    )
                    additional_prompt_camera = gr.Textbox(
                        label="é™„åŠ æç¤ºè¯",
                        value="",
                        placeholder="å¯åœ¨æ­¤æ·»åŠ é¢å¤–çš„æç¤ºè¯ï¼Œå°†è‡ªåŠ¨åˆå¹¶åˆ°ç”Ÿæˆçš„æç¤ºè¯ä¸­",
                        interactive=True
                    )
                    negative_prompt_camera = gr.Textbox(label="è´Ÿé¢æç¤ºè¯", value="")
                with gr.Accordion("å‚æ•°è®¾ç½®", open=True):
                    gr.Markdown("ä¸Šä¼ å›¾åƒååˆ†è¾¨ç‡è‡ªåŠ¨è®¡ç®—")
                    with gr.Row():
                        width_camera = gr.Slider(label="å®½åº¦", minimum=256, maximum=3072, step=16, value=1024)
                        height_camera = gr.Slider(label="é«˜åº¦", minimum=256, maximum=3072, step=16, value=1024)
                    with gr.Row():
                        exchange_button_camera = gr.Button("ğŸ”„ äº¤æ¢å®½é«˜")
                        scale_1_5_button_camera = gr.Button("ğŸ“ 1.5å€åˆ†è¾¨ç‡")
                    batch_images_camera = gr.Slider(label="æ‰¹é‡ç”Ÿæˆ", minimum=1, maximum=100, step=1, value=1)
                    num_inference_steps_camera = gr.Slider(label="é‡‡æ ·æ­¥æ•°ï¼ˆæ¨è4æ­¥ï¼‰", minimum=1, maximum=100, step=1, value=4)
                    true_cfg_scale_camera = gr.Slider(label="true cfg scale", minimum=1, maximum=10, step=0.1, value=1.0)
                    seed_param_camera = gr.Number(label="ç§å­ï¼Œè¯·è¾“å…¥è‡ªç„¶æ•°ï¼Œ-1ä¸ºéšæœº", value=-1)
            
            # Right column: Output
            with gr.Column(scale=1):
                info_camera = gr.Textbox(label="æç¤ºä¿¡æ¯", interactive=False)
                result_camera = gr.Gallery(label="ç”Ÿæˆç»“æœ", interactive=False)
                stop_button_camera = gr.Button("â¹ï¸ ä¸­æ­¢ç”Ÿæˆ", variant="stop")
                examples_dropdown_camera = gr.Dropdown(
                    label="æç¤ºè¯åº“", 
                    choices=load_examples("camera"),
                    interactive=True,
                    scale=5
                )
    # ControlNeté¢„å¤„ç†é¡µé¢
    with gr.Column(visible=False) as page_controlnet:
        with gr.TabItem("å›¾ç‰‡é¢„å¤„ç†"):
            with gr.Row():
                with gr.Column():
                    image_cont = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=400)
                    # é¢„å¤„ç†ä¸‹æ‹‰æ¡†å·²ç§»åˆ°é¡¶éƒ¨çš„æ¨¡å‹é€‰æ‹©åŒºåŸŸ
                    generate_button_cont = gr.Button("ğŸ–¼ï¸ å¼€å§‹ç”Ÿæˆ", variant='primary', scale=4)
                with gr.Column():
                    info_cont = gr.Textbox(label="æç¤ºä¿¡æ¯", interactive=False)
                    image_output_cont = gr.Image(label="ç”Ÿæˆç»“æœ", interactive=False)
                    with gr.Row():
                        send_to_i2i = gr.Button("ğŸ“¤ å‘é€åˆ°å›¾ç”Ÿå›¾", scale=1)
                        send_to_inp = gr.Button("ğŸ“¤ å‘é€åˆ°å±€éƒ¨é‡ç»˜", scale=1)
                    with gr.Row():
                        send_to_edit2 = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘1", scale=1)
                        send_to_edit3 = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘2", scale=1)
                        send_to_edit4 = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘3", scale=1)
                        send_to_edit5 = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘4", scale=1)
        with gr.TabItem("Open Pose Editor"):
            gr.HTML('<iframe src="https://zhuyu1997.github.io/open-pose-editor/" width="100%" height="800px" frameborder="0" style="border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);"></iframe>')
    # å›¾åº“é¡µé¢
    with gr.Column(visible=False) as page_gallery:
        with gr.Row():
            with gr.Column(scale=3):
                refresh_gallery_button = gr.Button("ğŸ”„ åˆ·æ–°å›¾åº“")
                gallery = gr.Gallery(label="å›¾åº“", columns=4, height="auto", object_fit="cover")
                selected_index = gr.Number(value=-1, visible=False)
            with gr.Column(scale=2):
                gallery_info = gr.Textbox(label="æç¤ºä¿¡æ¯", interactive=False)
                info_info = gr.Textbox(label="å›¾ç‰‡ä¿¡æ¯", lines=20, interactive=False)
        with gr.Row():
            send_to_i2i_gallery = gr.Button("ğŸ“¤ å‘é€åˆ°å›¾ç”Ÿå›¾")
            send_to_inp_gallery = gr.Button("ğŸ“¤ å‘é€åˆ°å±€éƒ¨é‡ç»˜")
            send_to_edit2_gallery = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘1")
            send_to_edit3_gallery = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘2")
            send_to_edit4_gallery = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘3")
            send_to_edit5_gallery = gr.Button("ğŸ“¤ å‘é€åˆ°å¤šå›¾ç¼–è¾‘4")
            send_to_cont_gallery = gr.Button("ğŸ“¤ å‘é€åˆ°ControlNeté¢„å¤„ç†")
    # è®¾ç½®é¡µé¢
    with gr.Column(visible=False) as page_settings:
        with gr.Row():
            with gr.Column():
                res_vram_tb = gr.Slider(label="ä¿ç•™æ˜¾å­˜", info="å•ä½MBï¼Œæ•°å€¼è¶Šå¤§ï¼Œæ˜¾å­˜å ç”¨è¶Šå°ï¼Œé€Ÿåº¦è¶Šæ…¢", minimum=0, maximum=80000, step=1, value=res_vram)
                with gr.Accordion("å¤šæ¨¡æ€APIè®¾ç½®", open=True):
                    openai_base_url_tb = gr.Textbox(label="BASE URL", info="è¯·è¾“å…¥BASE URLï¼Œä¾‹å¦‚ï¼šhttps://open.bigmodel.cn/api/paas/v4", value=openai_base_url)
                    openai_api_key_tb = gr.Textbox(label="API KEY", info="è¯·è¾“å…¥API KEYï¼Œæš—æ–‡æ˜¾ç¤º", value=openai_api_key, type="password")
                    with gr.Row():
                        model_name_tb = gr.Textbox(label="MODEL NAME", info="è¯·è¾“å…¥æ¨¡å‹åç§°ï¼Œéœ€è¦æ”¯æŒå›¾ç‰‡è¾“å…¥çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œä¾‹å¦‚ï¼šGLM-4.6V", value=model_name)
                        temperature_tb = gr.Slider(label="temperature", info="é‡‡æ ·æ¸©åº¦ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§å’Œåˆ›é€ æ€§", minimum=0, maximum=1, step=0.1, value=temperature)
                    with gr.Row():
                        top_p_tb = gr.Slider(label="top_p", info="æ ¸é‡‡æ ·ï¼ˆnucleus samplingï¼‰å‚æ•°ï¼Œæ˜¯temperatureé‡‡æ ·çš„æ›¿ä»£æ–¹æ³•", minimum=0, maximum=1, step=0.1, value=top_p)
                        max_tokens_tb = gr.Slider(label="max_tokens", info="æ¨¡å‹è¾“å‡ºçš„æœ€å¤§ä»¤ç‰Œï¼ˆtokenï¼‰æ•°é‡é™åˆ¶", minimum=1024, maximum=65536, step=1024, value=max_tokens)
                with gr.Accordion("åœ¨çº¿ç”Ÿå›¾APIè®¾ç½®", open=True):
                    modelscope_api_key_tb = gr.Textbox(label="é­”æ­çš„API KEY", info="ä½¿ç”¨é­”æ­åœ¨çº¿æ¨¡å‹æ—¶éœ€è¦ï¼Œè·å–åœ°å€https://modelscope.cn/my/myaccesstoken", value=modelscope_api_key, type="password")
                with gr.Accordion("å›¾ç‰‡ä¿å­˜è®¾ç½®", open=True):
                    image_format_tb = gr.Dropdown(label="å›¾ç‰‡ä¿å­˜æ ¼å¼", info="é€‰æ‹©ç”Ÿæˆå›¾ç‰‡çš„ä¿å­˜æ ¼å¼", choices=["png", "jpg", "webp"], value=image_format)
            with gr.Column():
                info_config = gr.Textbox(label="æç¤ºä¿¡æ¯", value="ä¿®æ”¹åè¯·ç‚¹å‡»ä¿å­˜è®¾ç½®ç”Ÿæ•ˆï¼›ç”Ÿæˆæ—¶ä»…ä½¿ç”¨å·²ä¿å­˜çš„è®¾ç½®ï¼Œä¸ä¼šä½¿ç”¨æœªä¿å­˜çš„æ›´æ”¹ã€‚", interactive=False)
                save_button = gr.Button("ğŸ’¾ ä¿å­˜è®¾ç½®", variant='primary')
                gr.Markdown("""å¤šæ¨¡æ€APIè®¾ç½®æ”¯æŒé€šç”¨ç±»OPENAIçš„APIï¼Œè¯·ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹ï¼Œå¦‚ï¼šGLM-4.6Vã€GLM-4.6V-Flashç­‰ï¼ˆéœ€è¦æ”¯æŒbase64ï¼‰ã€‚
                            å¯ç”³è¯·[æ™ºè°±API](https://www.bigmodel.cn/invite?icode=eKq1YoHsX6y4VhGIPJuOPGczbXFgPRGIalpycrEwJ28%3D)ã€‚
                            temperatureã€top_på’Œmax_tokensä¸‰ä¸ªå€¼ï¼Œé»˜è®¤æ˜¯GLM-4.6Vçš„æ¨èå€¼ã€‚
                            å¦‚æœæ›´æ¢æ¨¡å‹ï¼Œè¯·è‡ªè¡Œä¿®æ”¹ã€‚
                            ä¿å­˜è®¾ç½®é™¤äº†ä¿å­˜æ­¤é¡µé¢çš„è®¾ç½®ï¼Œè¿˜ä¼šä¿å­˜QIåŸºç¡€æ¨¡å‹å’ŒQIç¼–è¾‘æ¨¡å‹çš„è®¾ç½®ã€‚
                            """)
    # é¡µé¢åˆ‡æ¢æ—¶æ›´æ–°é¡µé¢å¯è§æ€§å’ŒåŸºç¡€æ¨¡å‹ä¸‹æ‹‰æ¡†çš„é€‰é¡¹
    def on_page_change(selected_page, current_model):
        """æ ¹æ®é€‰æ‹©çš„é¡µé¢æ›´æ–°é¡µé¢å¯è§æ€§å’ŒåŸºç¡€æ¨¡å‹ä¸‹æ‹‰æ¡†çš„é€‰é¡¹"""
        # åˆå§‹åŒ–æ‰€æœ‰é¡µé¢çš„å¯è§æ€§
        page_visibility = {
            "æ–‡ç”Ÿå›¾": False,
            "å›¾ç”Ÿå›¾": False,
            "å±€éƒ¨é‡ç»˜": False,
            "å¤šå›¾ç¼–è¾‘": False,
            "3Dç›¸æœºæ§åˆ¶": False,
            "ControlNeté¢„å¤„ç†": False,
            "å›¾åº“": False,
            "è®¾ç½®": False
        }
        
        # è®¾ç½®å½“å‰é¡µé¢ä¸ºå¯è§
        if selected_page in page_visibility:
            page_visibility[selected_page] = True
        
        # æ ¹æ®é¡µé¢åˆ¤æ–­ä½¿ç”¨å“ªä¸ªæ¨¡å‹åˆ—è¡¨
        choices = None
        new_value = None
        if selected_page == "æ–‡ç”Ÿå›¾":
            # æ–‡ç”Ÿå›¾ä½¿ç”¨å®Œæ•´æ¨¡å‹åˆ—è¡¨ï¼ˆåŒ…å«MS-Z-Image-Turboï¼‰
            choices = t2i_choices
            # æ£€æŸ¥å½“å‰å€¼æ˜¯å¦åœ¨æ–°åˆ—è¡¨ä¸­ï¼Œå¦‚æœåœ¨å°±ä¿æŒï¼Œå¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå€¼
            if current_model and current_model in choices:
                new_value = current_model
            else:
                new_value = choices[0] if choices else None
            # ç¡®ä¿ new_value åœ¨ choices ä¸­
            if new_value not in choices:
                new_value = choices[0] if choices else None
            model_update = gr.update(choices=choices, value=new_value)
        elif selected_page in ["å›¾ç”Ÿå›¾", "å±€éƒ¨é‡ç»˜"]:
            # å›¾ç”Ÿå›¾ã€å±€éƒ¨é‡ç»˜åªä½¿ç”¨æœ¬åœ°æ¨¡å‹
            choices = transformer_choices
            if current_model and current_model in choices:
                new_value = current_model
            else:
                new_value = choices[0] if choices else None
            # ç¡®ä¿ new_value åœ¨ choices ä¸­
            if new_value not in choices:
                new_value = choices[0] if choices else None
            model_update = gr.update(choices=choices, value=new_value)
        elif selected_page in ["å¤šå›¾ç¼–è¾‘", "3Dç›¸æœºæ§åˆ¶"]:
            # å¤šå›¾ç¼–è¾‘ã€3Dç›¸æœºæ§åˆ¶ä½¿ç”¨ç¼–è¾‘æ¨¡å‹åˆ—è¡¨
            choices = transformer_choices2
            if current_model and current_model in choices:
                new_value = current_model
            else:
                new_value = choices[0] if choices else None
            # ç¡®ä¿ new_value åœ¨ choices ä¸­
            if new_value not in choices:
                new_value = choices[0] if choices else None
            model_update = gr.update(choices=choices, value=new_value)
        elif selected_page == "ControlNeté¢„å¤„ç†":
            # ControlNeté¢„å¤„ç†ä½¿ç”¨é¢„å¤„ç†é€‰é¡¹åˆ—è¡¨
            choices = controlnet_processor_choices
            # å¦‚æœå½“å‰å€¼æ˜¯é¢„å¤„ç†é€‰é¡¹ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªé€‰é¡¹
            if current_model and isinstance(current_model, str) and current_model in choices:
                new_value = current_model
            else:
                new_value = choices[0] if choices else None
            # æœ€ç»ˆç¡®ä¿ new_value åœ¨ choices ä¸­ä¸”ä¸ä¸º None
            if not choices or new_value not in choices:
                new_value = choices[0] if choices else None
            model_update = gr.update(choices=choices, value=new_value)
        elif selected_page in ["å›¾åº“", "è®¾ç½®"]:
            # å›¾åº“å’Œè®¾ç½®é¡µé¢ï¼Œæ¨¡å‹é€‰æ‹©ä¸ºç©º
            model_update = gr.update(choices=[], value=None)
            new_value = None
        else:
            # å…¶ä»–é¡µé¢ä¿æŒå½“å‰é€‰é¡¹ï¼Œä¸æ›´æ–°æ¨¡å‹åˆ—è¡¨
            model_update = gr.update()
            new_value = current_model
        
        return (
            gr.update(visible=page_visibility["æ–‡ç”Ÿå›¾"]),  # page_t2i
            gr.update(visible=page_visibility["å›¾ç”Ÿå›¾"]),  # page_i2i
            gr.update(visible=page_visibility["å±€éƒ¨é‡ç»˜"]),  # page_inp
            gr.update(visible=page_visibility["å¤šå›¾ç¼–è¾‘"]),  # page_editplus
            gr.update(visible=page_visibility["3Dç›¸æœºæ§åˆ¶"]),  # page_camera
            gr.update(visible=page_visibility["ControlNeté¢„å¤„ç†"]),  # page_controlnet
            gr.update(visible=page_visibility["å›¾åº“"]),  # page_gallery
            gr.update(visible=page_visibility["è®¾ç½®"]),  # page_settings
            model_update,  # transformer_dropdown
            new_value  # current_model_value
        )
    
    # ä¿®æ”¹é¡µé¢åˆ‡æ¢å‡½æ•°ï¼Œåœ¨åˆ‡æ¢æ—¶ä¿å­˜æ¨¡å‹é€‰æ‹©
    def on_page_change_with_save(selected_page, current_model):
        """é¡µé¢åˆ‡æ¢æ—¶ï¼Œä¿å­˜å½“å‰æ¨¡å‹é€‰æ‹©åˆ°å¯¹åº”æ ‡ç­¾"""
        result = on_page_change(selected_page, current_model)
        # å¦‚æœå½“å‰æœ‰æ¨¡å‹é€‰æ‹©ï¼Œä¿å­˜åˆ°å¯¹åº”æ ‡ç­¾
        if current_model:
            if selected_page == "æ–‡ç”Ÿå›¾":
                save_tab_model("t2i", current_model)
            elif selected_page == "å›¾ç”Ÿå›¾":
                save_tab_model("i2i", current_model)
            elif selected_page == "å±€éƒ¨é‡ç»˜":
                save_tab_model("inp", current_model)
            elif selected_page == "å¤šå›¾ç¼–è¾‘":
                save_tab_model("editplus", current_model)
            elif selected_page == "3Dç›¸æœºæ§åˆ¶":
                save_tab_model("camera", current_model)
        return result
    
    page_dropdown.change(
        fn=on_page_change_with_save,
        inputs=[page_dropdown, current_model_value],
        outputs=[page_t2i, page_i2i, page_inp, page_editplus, page_camera, page_controlnet, page_gallery, page_settings, transformer_dropdown, current_model_value]
    )
    
    # å½“æ¨¡å‹ä¸‹æ‹‰æ¡†å€¼æ”¹å˜æ—¶ï¼Œæ›´æ–° State
    def update_model_state(selected_model):
        return selected_model
    
    transformer_dropdown.change(
        fn=update_model_state,
        inputs=[transformer_dropdown],
        outputs=[current_model_value]
    )
    
    # æ¨¡å‹è®¾ç½®
    refresh_button.click(
        fn=refresh_model,
        inputs=[],
        outputs=[transformer_dropdown, lora_dropdown, transformer_t2i, transformer_i2i, transformer_inp, transformer_editplus, transformer_camera]
    )
    # å½“åŸºç¡€æ¨¡å‹é€‰æ‹©æ”¹å˜æ—¶ï¼ŒåŒæ­¥æ›´æ–°æ‰€æœ‰TabItemçš„æ¨¡å‹é€‰æ‹©å™¨ï¼ˆä»…é™åŸºç¡€æ¨¡å‹TabItemï¼Œæ’é™¤MSé€‰é¡¹ï¼‰
    def sync_model_to_tabs(selected_model, current_page):
        """åŒæ­¥åŸºç¡€æ¨¡å‹é€‰æ‹©åˆ°æ‰€æœ‰åŸºç¡€æ¨¡å‹TabItemï¼Œå¹¶ä¿å­˜é…ç½®ï¼ˆMSé€‰é¡¹åªåŒæ­¥åˆ°æ–‡ç”Ÿå›¾ï¼‰"""
        if selected_model:
            # æ ¹æ®å½“å‰é¡µé¢ä¿å­˜åˆ°å¯¹åº”æ ‡ç­¾
            if current_page == "æ–‡ç”Ÿå›¾":
                save_tab_model("t2i", selected_model)
            elif current_page == "å›¾ç”Ÿå›¾":
                save_tab_model("i2i", selected_model)
            elif current_page == "å±€éƒ¨é‡ç»˜":
                save_tab_model("inp", selected_model)
            elif current_page == "å¤šå›¾ç¼–è¾‘":
                save_tab_model("editplus", selected_model)
            elif current_page == "3Dç›¸æœºæ§åˆ¶":
                save_tab_model("camera", selected_model)
            
            # ä¿å­˜åˆ°é…ç½®ï¼ˆåŸºç¡€æ¨¡å‹æ ‡ç­¾ï¼‰
            save_tab_model("t2i", selected_model)
            # MSé€‰é¡¹åªç”¨äºæ–‡ç”Ÿå›¾ï¼Œä¸åŒæ­¥åˆ°å…¶ä»–TabItem
            if selected_model not in ["MS-Qwen-Image", "MS-Qwen-Image-2512", "MS-Z-Image-Turbo"]:
                save_tab_model("i2i", selected_model)
                save_tab_model("inp", selected_model)
                return (
                    gr.Dropdown(value=selected_model),  # transformer_t2i
                    gr.Dropdown(value=selected_model),  # transformer_i2i
                    gr.Dropdown(value=selected_model),  # transformer_inp
                )
            else:
                # MSé€‰é¡¹åªæ›´æ–°æ–‡ç”Ÿå›¾
                return (
                    gr.Dropdown(value=selected_model),  # transformer_t2i
                    gr.Dropdown(),  # transformer_i2i (ä¸æ›´æ–°)
                    gr.Dropdown(),  # transformer_inp (ä¸æ›´æ–°)
                )
        return (
            gr.Dropdown(),  # transformer_t2i
            gr.Dropdown(),  # transformer_i2i
            gr.Dropdown(),  # transformer_inp
        )
    
    transformer_dropdown.change(
        fn=sync_model_to_tabs,
        inputs=[transformer_dropdown, page_dropdown],
        outputs=[transformer_t2i, transformer_i2i, transformer_inp]
    )
    # æ–‡ç”Ÿå›¾
    gr.on(
        triggers=[generate_button.click, prompt.submit, negative_prompt.submit, seed_param.submit],
        fn = generate_t2i,
        inputs = [
            prompt,
            negative_prompt,
            width,
            height,
            num_inference_steps,
            batch_images,
            true_cfg_scale, 
            seed_param,
            transformer_t2i,
            lora_dropdown, 
            lora_weights,
        ],
        outputs = [image_output, info]
    )
    enhance_button.click(
        fn=enhance_prompt, 
        inputs=[prompt], 
        outputs=[prompt, info]
    )
    exchange_button.click(
        fn=exchange_width_height, 
        inputs=[width, height], 
        outputs=[width, height, info]
    )
    scale_1_5_button.click(
        fn=scale_resolution_1_5,
        inputs=[width, height],
        outputs=[width, height, info]
    )
    save_example_button.click(
        fn=lambda prompt: save_example(prompt, "t2i"),
        inputs=[prompt],
        outputs=[examples_dropdown, info]
    )
    examples_dropdown.change(
        fn=lambda selected_example, current_prompt: f"{current_prompt} {selected_example.strip()}",
        inputs=[examples_dropdown, prompt],
        outputs=[prompt]
    )
    stop_button.click(
        fn=stop_generate, 
        inputs=[], 
        outputs=[info]
    )
    # å›¾ç”Ÿå›¾
    gr.on(
        triggers=[generate_button_i2i.click, prompt_i2i.submit, negative_prompt_i2i.submit, seed_param_i2i.submit],
        fn = generate_i2i,
        inputs = [
            image_i2i,
            prompt_i2i,
            negative_prompt_i2i,
            width_i2i,
            height_i2i,
            num_inference_steps_i2i,
            strength_i2i,
            batch_images_i2i,
            true_cfg_scale_i2i, 
            seed_param_i2i,
            transformer_i2i,
            lora_dropdown, 
            lora_weights,
        ],
        outputs = [image_output_i2i, info_i2i]
    )
    enhance_button_i2i.click(
        fn=enhance_prompt, 
        inputs=[prompt_i2i], 
        outputs=[prompt_i2i, info_i2i]
    )
    reverse_button_i2i.click(
        fn=enhance_prompt, 
        inputs=[prompt_i2i, image_i2i], 
        outputs=[prompt_i2i, info_i2i]
    )
    exchange_button_i2i.click(
        fn=exchange_width_height, 
        inputs=[width_i2i, height_i2i], 
        outputs=[width_i2i, height_i2i, info_i2i]
    )
    scale_1_5_button_i2i.click(
        fn=scale_resolution_1_5,
        inputs=[width_i2i, height_i2i],
        outputs=[width_i2i, height_i2i, info_i2i]
    )
    image_i2i.upload(
        fn=adjust_width_height, 
        inputs=[image_i2i], 
        outputs=[width_i2i, height_i2i, info_i2i]
    )
    save_example_button_i2i.click(
        fn=lambda prompt: save_example(prompt, "i2i"),
        inputs=[prompt_i2i],
        outputs=[examples_dropdown_i2i, info_i2i]
    )
    examples_dropdown_i2i.change(
        fn=lambda selected_example, current_prompt: f"{current_prompt} {selected_example.strip()}",
        inputs=[examples_dropdown_i2i, prompt_i2i],
        outputs=[prompt_i2i]
    )
    stop_button_i2i.click(
        fn=stop_generate, 
        inputs=[], 
        outputs=[info_i2i]
    )
    # å±€éƒ¨é‡ç»˜
    gr.on(
        triggers=[generate_button_inp.click, prompt_inp.submit, negative_prompt_inp.submit, seed_param_inp.submit],
        fn = generate_inp,
        inputs = [
            image_inp,
            prompt_inp,
            negative_prompt_inp,
            width_inp,
            height_inp,
            num_inference_steps_inp,
            strength_inp,
            batch_images_inp,
            true_cfg_scale_inp, 
            seed_param_inp,
            transformer_inp,
            lora_dropdown, 
            lora_weights,
        ],
        outputs = [image_output_inp, info_inp]
    )
    enhance_button_inp.click(
        fn=enhance_prompt, 
        inputs=[prompt_inp], 
        outputs=[prompt_inp, info_inp]
    )
    reverse_button_inp.click(
        fn=enhance_prompt, 
        inputs=[prompt_inp, image_inp], 
        outputs=[prompt_inp, info_inp]
    )
    exchange_button_inp.click(
        fn=exchange_width_height, 
        inputs=[width_inp, height_inp], 
        outputs=[width_inp, height_inp, info_inp]
    )
    scale_1_5_button_inp.click(
        fn=scale_resolution_1_5,
        inputs=[width_inp, height_inp],
        outputs=[width_inp, height_inp, info_inp]
    )
    image_inp.upload(
        fn=adjust_width_height, 
        inputs=[image_inp], 
        outputs=[width_inp, height_inp, info_inp]
    )
    save_example_button_inp.click(
        fn=lambda prompt: save_example(prompt, "inp"),
        inputs=[prompt_inp],
        outputs=[examples_dropdown_inp, info_inp]
    )
    examples_dropdown_inp.change(
        fn=lambda selected_example, current_prompt: f"{current_prompt} {selected_example.strip()}",
        inputs=[examples_dropdown_inp, prompt_inp],
        outputs=[prompt_inp]
    )
    stop_button_inp.click(
        fn=stop_generate, 
        inputs=[], 
        outputs=[info_inp]
    )
    # å¤šå›¾ç¼–è¾‘
    reference_count.change(
        fn=change_reference_count,
        inputs=[reference_count],
        outputs=[image_editplus3, image_editplus4, image_editplus5]
    )
    gr.on(
        triggers=[generate_button_editplus2.click, prompt_editplus2.submit, negative_prompt_editplus2.submit, seed_param_editplus2.submit],
        fn = generate_editplus2,
        inputs = [
            image_editplus2,
            image_editplus3,
            image_editplus4,
            image_editplus5,
            prompt_editplus2,
            negative_prompt_editplus2,
            width_editplus2,
            height_editplus2,
            num_inference_steps_editplus2,
            batch_images_editplus2,
            true_cfg_scale_editplus2, 
            seed_param_editplus2,
            transformer_dropdown,  # ä½¿ç”¨é¡¶éƒ¨çš„æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†ï¼Œè€Œä¸æ˜¯éšè—çš„ transformer_editplus
            lora_dropdown, 
            lora_weights,
        ],
        outputs = [image_output_editplus2, info_editplus2]
    )
    enhance_button_editplus2.click(
        fn=enhance_prompt_edit2, 
        inputs=[prompt_editplus2, image_editplus2, image_editplus3, image_editplus4, image_editplus5], 
        outputs=[prompt_editplus2, info_editplus2]
    )
    reverse_button_editplus2.click(
        fn=enhance_prompt, 
        inputs=[prompt_editplus2, image_editplus2], 
        outputs=[prompt_editplus2, info_editplus2]
    )
    exchange_button_editplus2.click(
        fn=exchange_width_height, 
        inputs=[width_editplus2, height_editplus2], 
        outputs=[width_editplus2, height_editplus2, info_editplus2]
    )
    scale_1_5_button_editplus2.click(
        fn=scale_resolution_1_5,
        inputs=[width_editplus2, height_editplus2],
        outputs=[width_editplus2, height_editplus2, info_editplus2]
    )
    image_editplus2.upload(
        fn=adjust_width_height_editplus2, 
        inputs=[image_editplus2], 
        outputs=[width_editplus2, height_editplus2, info_editplus2]
    )
    save_example_button_editplus2.click(
        fn=lambda prompt: save_example(prompt, "editplus"),
        inputs=[prompt_editplus2],
        outputs=[examples_dropdown_editplus2, info_editplus2]
    )
    examples_dropdown_editplus2.change(
        fn=lambda selected_example, current_prompt: f"{current_prompt} {selected_example.strip()}",
        inputs=[examples_dropdown_editplus2, prompt_editplus2],
        outputs=[prompt_editplus2]
    )
    stop_button_editplus2.click(
        fn=stop_generate, 
        inputs=[], 
        outputs=[info_editplus2]
    )
    # 3Dç›¸æœºæ§åˆ¶
    def update_prompt_from_sliders_camera(azimuth, elevation, distance):
        """Update prompt preview when sliders change."""
        prompt = build_camera_prompt(azimuth, elevation, distance)
        return prompt
    
    def sync_3d_to_sliders_camera(camera_value):
        """Sync 3D control changes to sliders."""
        if camera_value and isinstance(camera_value, dict):
            az = camera_value.get('azimuth', 0)
            el = camera_value.get('elevation', 0)
            dist = camera_value.get('distance', 1.0)
            prompt = build_camera_prompt(az, el, dist)
            return az, el, dist, prompt
        return gr.update(), gr.update(), gr.update(), gr.update()
    
    def sync_sliders_to_3d_camera(azimuth, elevation, distance):
        """Sync slider changes to 3D control."""
        return {"azimuth": azimuth, "elevation": elevation, "distance": distance}
    
    def update_3d_image_camera(image):
        """Update the 3D component with the uploaded image."""
        if image is None:
            return gr.update(imageUrl=None)
        # Convert PIL image to base64 data URL
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        data_url = f"data:image/png;base64,{img_str}"
        return gr.update(imageUrl=data_url)
    
    # Slider -> Prompt preview
    for slider in [azimuth_slider, elevation_slider, distance_slider]:
        slider.change(
            fn=update_prompt_from_sliders_camera,
            inputs=[azimuth_slider, elevation_slider, distance_slider],
            outputs=[prompt_preview_camera]
        )
    
    # 3D control -> Sliders + Prompt
    camera_3d.change(
        fn=sync_3d_to_sliders_camera,
        inputs=[camera_3d],
        outputs=[azimuth_slider, elevation_slider, distance_slider, prompt_preview_camera]
    )
    
    # Sliders -> 3D control
    for slider in [azimuth_slider, elevation_slider, distance_slider]:
        slider.release(
            fn=sync_sliders_to_3d_camera,
            inputs=[azimuth_slider, elevation_slider, distance_slider],
            outputs=[camera_3d]
        )
    
    # Prompt enhancement and reverse
    enhance_button_camera.click(
        fn=enhance_prompt, 
        inputs=[additional_prompt_camera, image_camera], 
        outputs=[additional_prompt_camera, info_camera]
    )
    reverse_button_camera.click(
        fn=enhance_prompt, 
        inputs=[additional_prompt_camera, image_camera], 
        outputs=[additional_prompt_camera, info_camera]
    )
    save_example_button_camera.click(
        fn=lambda prompt: save_example(prompt, "camera"),
        inputs=[additional_prompt_camera],
        outputs=[examples_dropdown_camera, info_camera]
    )
    examples_dropdown_camera.change(
        fn=lambda selected_example, current_prompt: f"{current_prompt} {selected_example.strip()}" if current_prompt else selected_example.strip(),
        inputs=[examples_dropdown_camera, additional_prompt_camera],
        outputs=[additional_prompt_camera]
    )
    
    # Generate button - æ”¯æŒå›è½¦è§¦å‘
    gr.on(
        triggers=[run_btn_camera.click, negative_prompt_camera.submit, seed_param_camera.submit],
        fn=generate_camera_edit,
        inputs=[image_camera, azimuth_slider, elevation_slider, distance_slider, negative_prompt_camera, 
                width_camera, height_camera, num_inference_steps_camera, 
                batch_images_camera, true_cfg_scale_camera, seed_param_camera, transformer_camera, 
                lora_dropdown, lora_weights, additional_prompt_camera],
        outputs=[result_camera, info_camera]
    )
    
    # Exchange width and height
    exchange_button_camera.click(
        fn=exchange_width_height, 
        inputs=[width_camera, height_camera], 
        outputs=[width_camera, height_camera, info_camera]
    )
    
    # Scale resolution 1.5x
    scale_1_5_button_camera.click(
        fn=scale_resolution_1_5,
        inputs=[width_camera, height_camera],
        outputs=[width_camera, height_camera, info_camera]
    )
    
    # Image upload -> update dimensions AND update 3D preview
    image_camera.upload(
        fn=update_dimensions_on_upload_camera,
        inputs=[image_camera],
        outputs=[width_camera, height_camera, info_camera]
    ).then(
        fn=update_3d_image_camera,
        inputs=[image_camera],
        outputs=[camera_3d]
    )
    
    # Also handle image clear
    image_camera.clear(
        fn=lambda: gr.update(imageUrl=None),
        outputs=[camera_3d]
    )
    
    stop_button_camera.click(
        fn=stop_generate, 
        inputs=[], 
        outputs=[info_camera]
    )
    # ControlNeté¢„å¤„ç†ï¼ˆä½¿ç”¨é¡¶éƒ¨çš„ transformer_dropdown ä½œä¸ºé¢„å¤„ç†é€‰æ‹©ï¼‰
    generate_button_cont.click(
        fn = generate_cont,
        inputs = [
            image_cont,
            transformer_dropdown,  # ä½¿ç”¨é¡¶éƒ¨çš„æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†ä½œä¸ºé¢„å¤„ç†é€‰æ‹©
        ],
        outputs = [image_output_cont, info_cont]
    )
    send_to_i2i.click(
        fn=lambda x: x,
        inputs=[image_output_cont],
        outputs=[image_i2i]
    )
    send_to_inp.click(
        fn=lambda x: {"background": x, "layers": [], "composite": x},
        inputs=[image_output_cont],
        outputs=[image_inp]
    )
    send_to_edit2.click(
        fn=lambda x: x,
        inputs=[image_output_cont],
        outputs=[image_editplus2]
    )
    send_to_edit3.click(
        fn=lambda x: x,
        inputs=[image_output_cont],
        outputs=[image_editplus3]
    )
    send_to_edit4.click(
        fn=lambda x: x,
        inputs=[image_output_cont],
        outputs=[image_editplus4]
    )
    send_to_edit5.click(
        fn=lambda x: x,
        inputs=[image_output_cont],
        outputs=[image_editplus5]
    )
    # å›¾åº“
    refresh_gallery_button.click(
        fn=refresh_gallery,
        inputs=[],
        outputs=[gallery, gallery_info]
    )
    demo.load(
        fn=refresh_gallery,
        inputs=[],
        outputs=[gallery, gallery_info]
    )
    gallery.select(
        fn=update_selection,
        outputs=selected_index
    ).then(
        fn=load_image_info_wrapper,
        inputs=[selected_index, gallery],
        outputs=[info_info]
    )
    send_to_i2i_gallery.click(
        fn=lambda idx, gallery: Image.open(gallery[idx][0]) if idx >= 0 and idx < len(gallery) else None,
        inputs=[selected_index, gallery],
        outputs=[image_i2i]
    )
    send_to_inp_gallery.click(
        fn=lambda idx, gallery: {"background": Image.open(gallery[idx][0]), "layers": [], "composite": Image.open(gallery[idx][0])} if idx >= 0 and idx < len(gallery) else None,
        inputs=[selected_index, gallery],
        outputs=[image_inp]
    )
    send_to_edit2_gallery.click(
        fn=lambda idx, gallery: Image.open(gallery[idx][0]) if idx >= 0 and idx < len(gallery) else None,
        inputs=[selected_index, gallery],
        outputs=[image_editplus2]
    )
    send_to_edit3_gallery.click(
        fn=lambda idx, gallery: Image.open(gallery[idx][0]) if idx >= 0 and idx < len(gallery) else None,
        inputs=[selected_index, gallery],
        outputs=[image_editplus3]
    )
    send_to_edit4_gallery.click(
        fn=lambda idx, gallery: Image.open(gallery[idx][0]) if idx >= 0 and idx < len(gallery) else None,
        inputs=[selected_index, gallery],
        outputs=[image_editplus4]
    )
    send_to_edit5_gallery.click(
        fn=lambda idx, gallery: Image.open(gallery[idx][0]) if idx >= 0 and idx < len(gallery) else None,
        inputs=[selected_index, gallery],
        outputs=[image_editplus5]
    )
    send_to_cont_gallery.click(
        fn=lambda idx, gallery: Image.open(gallery[idx][0]) if idx >= 0 and idx < len(gallery) else None,
        inputs=[selected_index, gallery],
        outputs=[image_cont]
    )
    # è®¾ç½®
    save_button.click(
        fn=save_openai_config,
        inputs=[transformer_dropdown, res_vram_tb, openai_base_url_tb, openai_api_key_tb, model_name_tb, temperature_tb, top_p_tb, max_tokens_tb, modelscope_api_key_tb, image_format_tb],
        outputs=[info_config],
    )


# æ—¥é—´æ¨¡å¼ + æŠ¤çœ¼é…è‰²ï¼šæš–ç°èƒŒæ™¯ã€æŸ”å’Œä¸»è‰²ã€é™ä½å¯¹æ¯”åº¦
_theme = (
    gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="slate",
        neutral_hue="stone",
        font=[gr.themes.GoogleFont("IBM Plex Sans")],
    ).set(
        body_background_fill="#fafafa",
        block_background_fill="#ffffff",
        block_border_color="#e8e6e1",
        body_text_color="#000000",
        block_label_text_color="#000000",
        block_title_text_color="#000000",
        input_background_fill="#f0f0f0",
        input_border_color="#b8d0e8",
        button_secondary_background_fill="#e8f0f8",
        button_secondary_background_fill_hover="#d5e6f5",
        button_secondary_text_color="#000000",
        button_secondary_border_color="#b8d0e8",
    )
)

if __name__ == "__main__": 
    head = '<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>'
    demo.launch(
        server_name=args.server_name, 
        server_port=find_port(args.server_port),
        share=args.share, 
        mcp_server=args.mcp_server,
        inbrowser=True,
        theme=_theme,
        css=css,
        head=head,
    )